---
title: Quiz
---

## Question 1:

대량의 컬럼형 데이터에 대해 분석 쿼리를 효율적으로 수행할 수 있는 데이터베이스를 구성하고자 합니다. 이 데이터 웨어하우스에 Amazon QuickSight와 같은 보고 및 대시보드 도구를 연결해 사용하려고 합니다. 가장 적합한 AWS 기술을 무엇입니까?

- .


## Question 2:

S3 버킷에 저장된 수많은 로그 파일이 저장되어 있습니다. 가능하다면 서버리스로 로그를 필터링하는 간단한 분석 작업을 수행하여 허용되지 않은 작업을 시도한 사용자를 찾으려고 합니다. 이런 경우에 사용할 수 있는 AWS 서비스는 무엇입니까?

- .


## Question 3:

솔루션 아키텍트로서 Redshift 클러스터에 대한 재해 복구 계획을 수립하는 업무를 맡았습니다. 어떤 작업을 해야 합니까?

- 자동 스냅샷을 활성화한 다음, Redshift 클러스터가 스냅샷을 다른 AWS 리전으로 자동 복사하도록 설정한다.


## Question 4:

Redshift에서 클러스터와 데이터 저장소 사이의 모든 COPY와 UNLOAD 트래픽이 VPC를 통하도록 강제하는 기능은 무엇입니까?

- 향상된 VPC 라우팅


## Question 5:

DynamoDB를 데이터 스토어로 사용하는 게임 웹 사이트를 운영하고 있습니다. 사용자들은 가능하다면 부분 일치하는 결과도 포함하여 이름으로 다른 게이머를 찾을 수 있는 검색 기능을 요청해왔습니다. 이 기능을 구현하는 데 적합한 AWS 기술은 무엇입니까?

- .


## Question 6:

이 AWS 서비스를 사용하면 몇 번의 클릭만으로 ETL(추출, 변환, 로드) 작업을 생성, 실행, 모니터링할 수 있습니다.

- .


## Question 7:

한 회사가 AWS를 사용해 자사의 공용 웹 사이트와 내부 애플리케이션을 호스팅하고 있습니다. 이들 웹 사이트와 애플리케이션에서는 수많은 로그 및 트레이스가 생성됩니다. 로그를 중앙 집중식으로 저장하여 실시간으로 검색하고 분석해 오류와 악의적인 시도를 감지할 수 있도록 만들어야 합니다. 로그를 효율적으로 저장하고 분석하는 데 도움이 되는 AWS 서비스는 무엇입니까?

- Amazon OpenSearch service


## Question 8:

………………………는 데이터 엔지니어와 분석가가 클러스터를 운영하거나 관리할 필요 없이 Apache Spark, Hive, Presto와 같은 오픈 소스 빅데이터 프레임워크로 구축된 애플리케이션을 쉽고 경제적으로 실행할 수 있게 해줍니다.

- .


## Question 9:

한 전자 상거래 기업은 주문 내역, 고객 정보, 이익, 전년도 매출과 같은 모든 과거 데이터를 Redshift 클러스터에 호스팅하고 있습니다. 전년도 이익과 총매출액을 표시하는 대시보드 및 보고서를 생성해야 한다는 요구 사항이 있었기 때문에, 내년에도 같은 요구 사항이 있을 것으로 보입니다. DevOps 팀은 이와 같은 대시보드를 정의할 수 있고 기본적으로 Redshift와 통합이 가능한 AWS 서비스를 찾는 업무를 맡았습니다. 가장 적합한 AWS 서비스는 무엇입니까?

- .


## Question 10:

AWS Glue에서 앞선 Glue ETL 작업 실행 중에 이미 처리된 데이터를 저장하고 추적할 수 있게 해주는 기능은 무엇입니까?

- .


## Question 11:

여러분이 DevOps 엔지니어로 일하고 있는 머신 러닝 기업은 S3 버킷에 3TB의 JSON 파일을 저장하고 있습니다. Amazon Athena를 사용해 이 파일에 대한 분석 작업을 수행해야 한다는 요구 사항이 있어 파일 포맷을 JSON에서 Apache Parquet으로 변환하는 방법을 찾고 있습니다. 가장 적합한 AWS 서비스는 무엇입니까?

- .


## Question 12:

온프레미스 Apache Kafka와 함께 사용하여 여러 웹 사이트로부터 클릭 스트림 이벤트 스트림을 받는 온프레미스 애플리케이션이 있습니다. 이 애플리케이션을 코드 변경 없이 가능한 한 빨리 마이그레이션해야 합니다. 애플리케이션을 EC2 인스턴스에 호스팅하기로 결정했을 때, Apache Kafka를 마이그레이션하기에 가장 적합한 서비스는 무엇입니까?

- .


## Question 13:

RDS, S3 버킷에 데이터가 저장되어 있고, 데이터에 대한 분석 작업을 수행할 수 있도록 AWS Lake Formation을 데이터 레이크로 사용해 수집, 이동 및 분류하고 있습니다. 회사에는 빅데이터 개발자와 ML 엔지니어가 아주 많기 때문에 민감 정보가 포함되었을 수도 있는 일부 데이터에 대해서는 접근을 제한하려고 합니다. 이런 경우 무엇을 사용해야 합니까?

- AWS Lake Formation Fine-Grained Access Control


## Question 14:

데이터 스트림에 대한 실시간 분석 작업을 수행하기에 가장 적합한 AWS 서비스는 무엇입니까?

- Amazon Kinesis Data Analytics